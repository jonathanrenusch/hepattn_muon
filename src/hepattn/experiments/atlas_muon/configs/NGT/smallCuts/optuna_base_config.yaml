seed_everything: 42

data:
  train_dir: /scratch/ml_training_data_2694000_hdf5_filtered_wp0990_maxtrk2_maxhit500
  val_dir: /scratch/ml_validation_data_144000_hdf5_filtered_wp0990_maxtrk2_maxhit500
  test_dir: /scratch/user/j/jorenusc/tracking/data_gen/ml_test_data_150K_processed
  
  num_workers: 24
  num_train: -1
  num_test: -1
  num_val: -1
  batch_size: 1024
  
  # ATLAS muon data parameters
  event_max_num_particles: &num_objects 2  # Typically fewer particles per event in muon data

  inputs:
    hit:
      # Global hit coordinates
      - spacePoint_globEdgeHighX
      - spacePoint_globEdgeHighY
      - spacePoint_globEdgeHighZ
      - spacePoint_globEdgeLowX
      - spacePoint_globEdgeLowY
      - spacePoint_globEdgeLowZ
      - spacePoint_time
      - spacePoint_driftR
      # Add covariance information
      - spacePoint_covXX
      - spacePoint_covXY
      - spacePoint_covYX
      - spacePoint_covYY
      # Add detector information
      - spacePoint_channel
      - spacePoint_layer
      - spacePoint_stationPhi
      - spacePoint_stationEta
      - spacePoint_stationIndex
      - spacePoint_technology
      # Add derived hit fields
      - r  # Radial distance
      - s  # 3D distance
      - theta  # Polar angle
      - phi  # Azimuthal angle

  targets:
    particle:
      - truthMuon_pt
      - truthMuon_q
      - truthMuon_eta
      - truthMuon_phi

trainer:
  # Training stuff here
  max_epochs: 50
  num_sanity_val_steps: 1
  accelerator: gpu
  precision: bf16-mixed
  log_every_n_steps: 50 
  default_root_dir: logs
  gradient_clip_val: 0.1
  enable_progress_bar: true

  # Callbacks for optuna optimization
  callbacks:
    - class_path: hepattn.callbacks.InferenceTimer
    - class_path: hepattn.callbacks.SaveConfig
    - class_path: hepattn.callbacks.Checkpoint
      init_args:
        monitor: val/loss
        mode: min
        save_top_k: 1
    - class_path: hepattn.callbacks.PredictionWriter
      init_args:
        write_inputs: false
        write_outputs: true
        write_preds: true
        write_targets: false
        write_losses: false
    - class_path: lightning.pytorch.callbacks.ModelSummary
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    - class_path: lightning.pytorch.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 50
    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: val/loss
        patience: 5
        min_delta: 0.0
        mode: min
        verbose: True

model:
  optimizer: Lion
  
  # Learning rate schedule configuration
  lrs_config:
    initial: 1e-5
    max: 5e-5
    end: 1e-5
    pct_start: 0.05
    skip_scheduler: false
    weight_decay: 1e-5
  
  # Whether to use multi task learning or not
  mtl: false

  # Static model configuration that won't be optimized
  model:
    class_path: hepattn.models.MaskFormer
    init_args:
      input_sort_field: phi
      
      input_nets:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: hepattn.models.InputNet
              init_args:
                input_name: hit
                fields:
                  # Global hit coordinates
                  - spacePoint_globEdgeHighX
                  - spacePoint_globEdgeHighY
                  - spacePoint_globEdgeHighZ
                  - spacePoint_globEdgeLowX
                  - spacePoint_globEdgeLowY
                  - spacePoint_globEdgeLowZ
                  - spacePoint_time
                  - spacePoint_driftR
                  # Add covariance information
                  - spacePoint_covXX
                  - spacePoint_covXY
                  - spacePoint_covYX
                  - spacePoint_covYY
                  # Add detector information
                  - spacePoint_channel
                  - spacePoint_layer
                  - spacePoint_stationPhi
                  - spacePoint_stationEta
                  - spacePoint_technology
                  - spacePoint_stationIndex
                  # Add derived hit fields
                  - r  # Radial distance
                  - s  # 3D distance
                  - theta  # Polar angle
                  - phi  # Azimuthal angle
                net:
                  class_path: hepattn.models.Dense
                  init_args:
                    input_size: 22
                    activation: null  # If null, defaults to SwiGLU()
                    bias: true  # Whether to use bias in linear layers
                    norm_input: true  # Whether to apply LayerNorm to input
                posenc:
                  class_path: hepattn.models.posenc.PositionEncoder
                  init_args:
                    input_name: hit
                    fields:
                      - r
                      - theta
                      - phi

      # Static encoder config - only num_layers and dim will be optimized
      encoder:
        class_path: hepattn.models.Encoder
        init_args:
          attn_type: flash-varlen
          hybrid_norm: true
          value_residual: true
          attn_kwargs:
            num_heads: 8
      
      # Static decoder config - only num_decoder_layers will be optimized
      decoder:
        mask_attention: true
        use_query_masks: false
        decoder_layer_config:
          norm: RMSNorm
          attn_kwargs: 
            num_heads: 8

      matcher:
        class_path: hepattn.models.matcher.Matcher
        init_args:
          default_solver: scipy
          adaptive_solver: false
          adaptive_check_interval: 1000
          parallel_solver: true
          n_jobs: 16

      # Tasks configuration - only costs, losses, and dense_kwargs will be optimized
      tasks:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: hepattn.models.task.ObjectValidTask
              init_args:
                name: track_valid
                input_object: query
                output_object: track
                target_object: particle
                null_weight: 0.1
                mask_queries: false
                dense_kwargs:
                  activation: null  # If null, defaults to SwiGLU()
                  dropout: 0.3  # Dropout probability
                  bias: true  # Whether to use bias in linear layers
                  norm_input: true  # Whether to apply LayerNorm to input
            - class_path: hepattn.models.task.ObjectHitMaskTask
              init_args:
                name: track_hit_valid
                input_constituent: hit
                input_object: query
                output_object: track
                target_object: particle
                null_weight: 0.1
                dense_kwargs:
                  activation: null  # If null, defaults to SwiGLU()
                  dropout: 0.3  # Dropout probability
                  bias: true  # Whether to use bias in linear layers
                  norm_input: true  # Whether to apply LayerNorm to input
            - class_path: hepattn.models.task.ObjectRegressionTask
              init_args:
                name: parameter_regression
                input_object: query
                output_object: track
                target_object: particle
                fields:
                - truthMuon_eta
                - truthMuon_phi
                - truthMuon_pt
                dense_kwargs:
                  activation: null  # If null, defaults to SwiGLU()
                  dropout: 0.3  # Dropout probability
                  bias: true  # Whether to use bias in linear layers
                  norm_input: true  # Whether to apply LayerNorm to input
            - class_path: hepattn.models.task.ObjectChargeClassificationTask
              init_args:
                name: charge_classification
                input_object: query
                output_object: track
                target_object: particle
                field: truthMuon_q
                dense_kwargs:
                  activation: null  # If null, defaults to SwiGLU()
                  dropout: 0.3  # Dropout probability
                  bias: true  # Whether to use bias in linear layers
                  norm_input: true  # Whether to apply LayerNorm to input