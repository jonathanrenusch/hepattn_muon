{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80f73387",
   "metadata": {},
   "source": [
    "## printing. out columns names for hits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7033a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 14)\n",
      "\n",
      "Column Names and Types:\n",
      "spacePoint_PositionX     object\n",
      "spacePoint_PositionY     object\n",
      "spacePoint_PositionZ     object\n",
      "spacePoint_covXX         object\n",
      "spacePoint_covXY         object\n",
      "spacePoint_covYX         object\n",
      "spacePoint_covYY         object\n",
      "spacePoint_channel       object\n",
      "spacePoint_driftR        object\n",
      "spacePoint_layer         object\n",
      "spacePoint_stationPhi    object\n",
      "spacePoint_stationEta    object\n",
      "spacePoint_technology    object\n",
      "spacePoint_truthLink     object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "                                spacePoint_PositionX  \\\n",
      "0  [406.6566467285156, 433.2040710449219, -527.50...   \n",
      "1  [-2.7530102763434483e-12, -2.289870983801512e-...   \n",
      "2  [4.068200203793948e-12, 3.6176484984745683e-12...   \n",
      "3  [-2.9803839517866804e-12, -2.298262925456984e-...   \n",
      "4  [-4.117252112162406e-12, -4.117252112162406e-1...   \n",
      "\n",
      "                                spacePoint_PositionY  \\\n",
      "0  [4276.15380859375, 4314.0986328125, -3032.25, ...   \n",
      "1  [-1664.23876953125, -1634.2037353515625, -1544...   \n",
      "2  [1345.271240234375, 1330.2537841796875, 1315.2...   \n",
      "3  [-2985.77880859375, -2234.90380859375, -2204.8...   \n",
      "4  [1949.2562255859375, 1979.291259765625, 1964.2...   \n",
      "\n",
      "                                spacePoint_PositionZ  \\\n",
      "0  [810.75, 834.5499877929688, -334.1799926757812...   \n",
      "1  [-152.04107666015625, -100.01897430419922, 100...   \n",
      "2  [-152.04107666015625, -126.02997589111328, -10...   \n",
      "3  [-152.04107666015625, -152.04107666015625, -15...   \n",
      "4  [-152.04107666015625, -152.04107666015625, -12...   \n",
      "\n",
      "                                    spacePoint_covXX  \\\n",
      "0  [212.8126678466797, 212.75860595703125, 204.25...   \n",
      "1  [1116720.5, 1116720.5, 1194102.5, 1194102.5, 1...   \n",
      "2  [2324862.5, 2216376.5, 2216376.5, 2216376.5, 2...   \n",
      "3  [768690.5625, 969732.5625, 969732.5625, 768690...   \n",
      "4  [2549610.5, 2549610.5, 2549610.5, 2549610.5, 2...   \n",
      "\n",
      "                                    spacePoint_covXY  \\\n",
      "0  [-3.256887674331665, -3.4388718605041504, -1.5...   \n",
      "1  [3.409173720663388e-27, 3.409173720663388e-27,...   \n",
      "2  [-1.2905579382938015e-10, -1.2303361107690591e...   \n",
      "3  [2.3466922889763874e-27, 2.960442058456873e-27...   \n",
      "4  [7.783563440439394e-27, 7.783563440439394e-27,...   \n",
      "\n",
      "                                    spacePoint_covYX  \\\n",
      "0  [-5.383260250091553, -5.379716873168945, -5.94...   \n",
      "1  [-1.8014108697628235e-26, -1.8014108697628235e...   \n",
      "2  [-1.2905579382938015e-10, -1.2303361107690591e...   \n",
      "3  [-1.2399946642913645e-26, -1.564300697994369e-...   \n",
      "4  [-4.1128428096127816e-26, -4.1128428096127816e...   \n",
      "\n",
      "                                    spacePoint_covYY  \\\n",
      "0  [130.89346313476562, 130.9053955078125, 202.72...   \n",
      "1  [0.041016630828380585, 0.035328418016433716, 0...   \n",
      "2  [0.042587246745824814, 0.04098178818821907, 0....   \n",
      "3  [0.0058540478348731995, 0.026762312278151512, ...   \n",
      "4  [0.006527998950332403, 0.00685542169958353, 0....   \n",
      "\n",
      "                                  spacePoint_channel  \\\n",
      "0  [12, 13, 10, 10, 11, 11, 9, 4, 9, 24, 24, 25, ...   \n",
      "1  [47, 48, 51, 51, 52, 48, 21, 48, 20, 48, 21, 1...   \n",
      "2  [33, 32, 32, 26, 27, 9, 41, 42, 9, 41, 10, 42,...   \n",
      "3  [3, 28, 29, 2, 29, 3, 5, 5, 6, 29, 29, 30, 34,...   \n",
      "4  [4, 5, 4, 5, 5, 9, 9, 9, 10, 34, 34, 35, 36, 4...   \n",
      "\n",
      "                                   spacePoint_driftR  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [3.23608136177063, 3.7703211307525635, 5.00178...   \n",
      "2  [4.948145866394043, 4.94598913192749, 5.736634...   \n",
      "3  [10.65999984741211, 4.394438743591309, 12.6615...   \n",
      "4  [14.61763858795166, 13.852466583251953, 12.999...   \n",
      "\n",
      "                                    spacePoint_layer  \\\n",
      "0  [1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 2, 3, 4, 5, 6, ...   \n",
      "1  [1, 3, 4, 5, 6, 1, 1, 2, 2, 3, 3, 4, 4, 5, 6, ...   \n",
      "2  [1, 2, 3, 4, 4, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5, ...   \n",
      "3  [1, 1, 1, 2, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, ...   \n",
      "4  [1, 1, 2, 2, 3, 4, 5, 6, 6, 1, 2, 2, 3, 4, 4, ...   \n",
      "\n",
      "                               spacePoint_stationPhi  \\\n",
      "0  [36, 36, 8, 8, 8, 8, 8, 5, 5, 3, 3, 3, 3, 3, 3...   \n",
      "1  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...   \n",
      "2  [4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
      "3  [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, ...   \n",
      "4  [8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 2, 2, 2, ...   \n",
      "\n",
      "                               spacePoint_stationEta  \\\n",
      "0  [5, 5, -2, -2, -2, -2, -2, -2, -2, 4, 4, 4, 4,...   \n",
      "1  [2, 2, 2, 2, 2, 4, 5, 4, 5, 4, 5, 5, 5, 5, 5, ...   \n",
      "2  [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, ...   \n",
      "3  [2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, ...   \n",
      "4  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...   \n",
      "\n",
      "                               spacePoint_technology  \\\n",
      "0  [3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, ...   \n",
      "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                spacePoint_truthLink  \n",
      "0  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "1  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "2  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "3  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "4  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   spacePoint_PositionX   1000 non-null   object\n",
      " 1   spacePoint_PositionY   1000 non-null   object\n",
      " 2   spacePoint_PositionZ   1000 non-null   object\n",
      " 3   spacePoint_covXX       1000 non-null   object\n",
      " 4   spacePoint_covXY       1000 non-null   object\n",
      " 5   spacePoint_covYX       1000 non-null   object\n",
      " 6   spacePoint_covYY       1000 non-null   object\n",
      " 7   spacePoint_channel     1000 non-null   object\n",
      " 8   spacePoint_driftR      1000 non-null   object\n",
      " 9   spacePoint_layer       1000 non-null   object\n",
      " 10  spacePoint_stationPhi  1000 non-null   object\n",
      " 11  spacePoint_stationEta  1000 non-null   object\n",
      " 12  spacePoint_technology  1000 non-null   object\n",
      " 13  spacePoint_truthLink   1000 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 109.5+ KB\n",
      "\n",
      "Summary Statistics:\n",
      "                                     spacePoint_PositionX  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [406.6566467285156, 433.2040710449219, -527.50...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                     spacePoint_PositionY  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [4276.15380859375, 4314.0986328125, -3032.25, ...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                     spacePoint_PositionZ  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [810.75, 834.5499877929688, -334.1799926757812...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                         spacePoint_covXX  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [212.8126678466797, 212.75860595703125, 204.25...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                         spacePoint_covXY  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [-3.256887674331665, -3.4388718605041504, -1.5...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                         spacePoint_covYX  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [-5.383260250091553, -5.379716873168945, -5.94...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                         spacePoint_covYY  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [130.89346313476562, 130.9053955078125, 202.72...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                       spacePoint_channel  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [12, 13, 10, 10, 11, 11, 9, 4, 9, 24, 24, 25, ...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                        spacePoint_driftR  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                         spacePoint_layer  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 2, 3, 4, 5, 6, ...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                    spacePoint_stationPhi  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [36, 36, 8, 8, 8, 8, 8, 5, 5, 3, 3, 3, 3, 3, 3...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                    spacePoint_stationEta  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [5, 5, -2, -2, -2, -2, -2, -2, -2, 4, 4, 4, 4,...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                    spacePoint_technology  \\\n",
      "count                                                1000   \n",
      "unique                                               1000   \n",
      "top     [3, 3, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, ...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                     spacePoint_truthLink  \n",
      "count                                                1000  \n",
      "unique                                               1000  \n",
      "top     [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
      "freq                                                    1  \n",
      "\n",
      "Detailed column analysis:\n",
      "\n",
      "spacePoint_PositionX:\n",
      "  - Type: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[col]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Unique values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnunique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Sample values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[col]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/base.py:1063\u001b[0m, in \u001b[0;36mIndexOpsMixin.nunique\u001b[0;34m(self, dropna)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnunique\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m    Return number of unique elements in the object.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m    4\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m     uniqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n\u001b[1;32m   1065\u001b[0m         uniqs \u001b[38;5;241m=\u001b[39m remove_na_arraylike(uniqs)\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7248\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Load the parquet file\n",
    "file_path = \"/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/data/hits0to1000.parquet\"\n",
    "\n",
    "# Read the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Print basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names and Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for any nested structures or special data types\n",
    "print(\"\\nDetailed column analysis:\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  - Type: {df[col].dtype}\")\n",
    "    print(f\"  - Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  - Sample values: {df[col].head(3).tolist()}\")\n",
    "    if df[col].dtype == 'object':\n",
    "        print(f\"  - Sample string lengths: {[len(str(x)) for x in df[col].head(3)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa73987",
   "metadata": {},
   "source": [
    "## Printing out column names for tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa5ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (1000, 4)\n",
      "\n",
      "Column Names and Types:\n",
      "truthMuon_pt     object\n",
      "truthMuon_eta    object\n",
      "truthMuon_phi    object\n",
      "truthMuon_q      object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "                               truthMuon_pt  \\\n",
      "0  [12.811131477355957, 12.308981895446777]   \n",
      "1    [15.651595115661621, 13.2050199508667]   \n",
      "2    [7.682015895843506, 9.074707984924316]   \n",
      "3    [6.626306533813477, 6.703860282897949]   \n",
      "4      [6.237548828125, 7.2003984451293945]   \n",
      "\n",
      "                                 truthMuon_eta  \\\n",
      "0   [-1.7902064323425293, -1.5814238786697388]   \n",
      "1   [-1.5253889560699463, -1.4375003576278687]   \n",
      "2    [-2.3908376693725586, -2.036024808883667]   \n",
      "3  [-0.21686002612113953, 0.04161323606967926]   \n",
      "4    [-2.0476503372192383, -1.959127426147461]   \n",
      "\n",
      "                                 truthMuon_phi truthMuon_q  \n",
      "0    [-2.186328887939453, -2.3159706592559814]     [1, -1]  \n",
      "1     [2.8516454696655273, 3.0480597019195557]     [-1, 1]  \n",
      "2      [1.9580662250518799, 2.056658983230591]     [1, -1]  \n",
      "3  [-0.16181595623493195, -0.5483758449554443]     [-1, 1]  \n",
      "4   [-1.0130852460861206, -0.5566835999488831]     [-1, 1]  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   truthMuon_pt   1000 non-null   object\n",
      " 1   truthMuon_eta  1000 non-null   object\n",
      " 2   truthMuon_phi  1000 non-null   object\n",
      " 3   truthMuon_q    1000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 31.4+ KB\n",
      "\n",
      "Summary Statistics:\n",
      "                                    truthMuon_pt  \\\n",
      "count                                       1000   \n",
      "unique                                      1000   \n",
      "top     [12.811131477355957, 12.308981895446777]   \n",
      "freq                                           1   \n",
      "\n",
      "                                     truthMuon_eta  \\\n",
      "count                                         1000   \n",
      "unique                                        1000   \n",
      "top     [-1.7902064323425293, -1.5814238786697388]   \n",
      "freq                                             1   \n",
      "\n",
      "                                    truthMuon_phi truthMuon_q  \n",
      "count                                        1000        1000  \n",
      "unique                                       1000         768  \n",
      "top     [-2.186328887939453, -2.3159706592559814]         [1]  \n",
      "freq                                            1         121  \n",
      "\n",
      "Detailed column analysis:\n",
      "\n",
      "truthMuon_pt:\n",
      "  - Type: object\n",
      "                                    truthMuon_pt  \\\n",
      "count                                       1000   \n",
      "unique                                      1000   \n",
      "top     [12.811131477355957, 12.308981895446777]   \n",
      "freq                                           1   \n",
      "\n",
      "                                     truthMuon_eta  \\\n",
      "count                                         1000   \n",
      "unique                                        1000   \n",
      "top     [-1.7902064323425293, -1.5814238786697388]   \n",
      "freq                                             1   \n",
      "\n",
      "                                    truthMuon_phi truthMuon_q  \n",
      "count                                        1000        1000  \n",
      "unique                                       1000         768  \n",
      "top     [-2.186328887939453, -2.3159706592559814]         [1]  \n",
      "freq                                            1         121  \n",
      "\n",
      "Detailed column analysis:\n",
      "\n",
      "truthMuon_pt:\n",
      "  - Type: object\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[col]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Unique values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnunique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - Sample values: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[col]\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df[col]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/base.py:1063\u001b[0m, in \u001b[0;36mIndexOpsMixin.nunique\u001b[0;34m(self, dropna)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnunique\u001b[39m(\u001b[38;5;28mself\u001b[39m, dropna: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;124;03m    Return number of unique elements in the object.\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m    4\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1063\u001b[0m     uniqs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dropna:\n\u001b[1;32m   1065\u001b[0m         uniqs \u001b[38;5;241m=\u001b[39m remove_na_arraylike(uniqs)\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7248\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.unique\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7195\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable._unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Load the parquet file\n",
    "file_path = \"/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/data/tracks0to1000.parquet\"\n",
    "\n",
    "# Read the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Print basic information about the dataset\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names and Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for any nested structures or special data types\n",
    "print(\"\\nDetailed column analysis:\")\n",
    "for col in df.columns:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  - Type: {df[col].dtype}\")\n",
    "    print(f\"  - Unique values: {df[col].nunique()}\")\n",
    "    print(f\"  - Sample values: {df[col].head(3).tolist()}\")\n",
    "    if df[col].dtype == 'object':\n",
    "        print(f\"  - Sample string lengths: {[len(str(x)) for x in df[col].head(3)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cf289c",
   "metadata": {},
   "source": [
    "## Investigating row groups on more global level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2956b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "File: hits20to30.parquet\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Failed to open local file '/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/hits20to30.parquet'. Detail: [errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Read parquet file metadata\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m parquet_file \u001b[38;5;241m=\u001b[39m \u001b[43mpq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParquetFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of row groups: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparquet_file\u001b[38;5;241m.\u001b[39mnum_row_groups\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal rows: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparquet_file\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mnum_rows\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pyarrow/parquet/core.py:313\u001b[0m, in \u001b[0;36mParquetFile.__init__\u001b[0;34m(self, source, metadata, common_metadata, read_dictionary, memory_map, buffer_size, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, filesystem, page_checksum_verification)\u001b[0m\n\u001b[1;32m    310\u001b[0m filesystem, source \u001b[38;5;241m=\u001b[39m _resolve_filesystem_and_path(\n\u001b[1;32m    311\u001b[0m     source, filesystem, memory_map\u001b[38;5;241m=\u001b[39mmemory_map)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filesystem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 313\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_input_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_source \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# We opened it here, ensure we close it.\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreader \u001b[38;5;241m=\u001b[39m ParquetReader()\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pyarrow/_fs.pyx:789\u001b[0m, in \u001b[0;36mpyarrow._fs.FileSystem.open_input_file\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/root_env/lib/python3.11/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Failed to open local file '/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/hits20to30.parquet'. Detail: [errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Check parquet file metadata for both files\n",
    "files = [\n",
    "    \"/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/hits20to30.parquet\",\n",
    "    \"/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed/tracks20to30.parquet\"\n",
    "]\n",
    "\n",
    "for file_path in files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"File: {file_path.split('/')[-1]}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Read parquet file metadata\n",
    "    parquet_file = pq.ParquetFile(file_path)\n",
    "    \n",
    "    print(f\"Number of row groups: {parquet_file.num_row_groups}\")\n",
    "    print(f\"Total rows: {parquet_file.metadata.num_rows}\")\n",
    "    print(f\"Total columns: {parquet_file.metadata.num_columns}\")\n",
    "    \n",
    "    # Show row group details\n",
    "    for i in range(parquet_file.num_row_groups):\n",
    "        row_group = parquet_file.metadata.row_group(i)\n",
    "        print(f\"\\nRow Group {i}:\")\n",
    "        print(f\"  - Rows: {row_group.num_rows}\")\n",
    "        print(f\"  - Total byte size: {row_group.total_byte_size}\")\n",
    "        \n",
    "        # Calculate compressed size by summing all columns\n",
    "        compressed_size = sum(row_group.column(j).total_compressed_size for j in range(row_group.num_columns))\n",
    "        print(f\"  - Compressed size: {compressed_size}\")\n",
    "        \n",
    "        compression_ratio = row_group.total_byte_size / compressed_size if compressed_size > 0 else 0\n",
    "        print(f\"  - Compression ratio: {compression_ratio:.2f}\")\n",
    "    \n",
    "    print(f\"\\nSchema:\")\n",
    "    print(parquet_file.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1700b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65a4adc6",
   "metadata": {},
   "source": [
    "## Reading and Exploring the New Metadata Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cf543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "YAML METADATA STRUCTURE\n",
      "============================================================\n",
      "\n",
      "Processing Summary:\n",
      "  total_excluded_tracks: 170\n",
      "  total_tracks_processed: 2309\n",
      "  excluded_tracks_percentage: 7.362494586401039\n",
      "  total_excluded_events: 246\n",
      "  total_events_processed: 1500\n",
      "  excluded_events_percentage: 16.400000000000002\n",
      "  valid_events: 1254\n",
      "  valid_tracks: 2139\n",
      "  average_tracks_per_event: 1.7057416267942584\n",
      "  processing_status: Complete\n",
      "\n",
      "Processing Parameters:\n",
      "  pt_threshold: 5.0\n",
      "  eta_threshold: 2.7\n",
      "  num_hits_threshold: 3\n",
      "  num_events_per_file: 1000\n",
      "\n",
      "Event Mapping Info:\n",
      "  Description: Event indices stored in separate numpy files for efficient access\n",
      "  Total events: 1254\n",
      "  Total chunks: 2\n",
      "\n",
      "  Index files:\n",
      "    global_event_ids: event_global_ids.npy\n",
      "    file_indices: event_file_indices.npy\n",
      "    row_indices: event_row_indices.npy\n",
      "    num_hits: event_num_hits.npy\n",
      "    num_tracks: event_num_tracks.npy\n",
      "    chunk_info: chunk_info.npy\n",
      "\n",
      "  First few chunk summaries:\n",
      "    Chunk 0:\n",
      "      hits_file: data/hits0to1000.parquet\n",
      "      tracks_file: data/tracks0to1000.parquet\n",
      "      event_count: 1000\n",
      "      start_event: 0\n",
      "      end_event: 1000\n",
      "    Chunk 1:\n",
      "      hits_file: data/hits1000to1254.parquet\n",
      "      tracks_file: data/tracks1000to1254.parquet\n",
      "      event_count: 254\n",
      "      start_event: 1000\n",
      "      end_event: 1254\n",
      "\n",
      "Processed Files (3):\n",
      "  1. /home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200/JpsiPU200R4500.root\n",
      "  2. /home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200/ZmumuPU200R4500.root\n",
      "  3. /home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200/ttbarPU200R4500.root\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Path to the dataset directory\n",
    "dataset_dir = \"/home/iwsatlas1/jrenusch/master_thesis/tracking/data/train_setPU200_processed\"\n",
    "\n",
    "# Read the main metadata YAML file\n",
    "metadata_file = os.path.join(dataset_dir, 'metadata.yaml')\n",
    "if os.path.exists(metadata_file):\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"YAML METADATA STRUCTURE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display processing summary\n",
    "    print(\"\\nProcessing Summary:\")\n",
    "    for key, value in metadata['processing_summary'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Display processing parameters\n",
    "    print(\"\\nProcessing Parameters:\")\n",
    "    for key, value in metadata['processing_parameters'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Display event mapping info\n",
    "    print(\"\\nEvent Mapping Info:\")\n",
    "    event_mapping = metadata['event_mapping']\n",
    "    print(f\"  Description: {event_mapping['description']}\")\n",
    "    print(f\"  Total events: {event_mapping['total_events']}\")\n",
    "    print(f\"  Total chunks: {event_mapping['total_chunks']}\")\n",
    "    \n",
    "    print(\"\\n  Index files:\")\n",
    "    for key, value in event_mapping['index_files'].items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    print(\"\\n  First few chunk summaries:\")\n",
    "    for i, chunk in enumerate(event_mapping['chunk_summary'][:3]):\n",
    "        print(f\"    Chunk {i}:\")\n",
    "        for key, value in chunk.items():\n",
    "            print(f\"      {key}: {value}\")\n",
    "    \n",
    "    # Display processed files\n",
    "    print(f\"\\nProcessed Files ({len(metadata['processed_files'])}):\")\n",
    "    for i, file_path in enumerate(metadata['processed_files']):\n",
    "        print(f\"  {i+1}. {file_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Metadata file not found at: {metadata_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b13c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NUMPY INDEX ARRAYS\n",
      "============================================================\n",
      "\n",
      "Global event IDs (event_global_ids.npy):\n",
      "  Shape: (1254,)\n",
      "  Data type: int32\n",
      "  Size in MB: 0.00\n",
      "  First 10 values: [0 1 2 3 4 5 6 7 8 9]\n",
      "  Last 10 values: [1244 1245 1246 1247 1248 1249 1250 1251 1252 1253]\n",
      "  Min: 0, Max: 1253\n",
      "\n",
      "File indices (which chunk) (event_file_indices.npy):\n",
      "  Shape: (1254,)\n",
      "  Data type: int16\n",
      "  Size in MB: 0.00\n",
      "  First 10 values: [0 0 0 0 0 0 0 0 0 0]\n",
      "  Last 10 values: [1 1 1 1 1 1 1 1 1 1]\n",
      "  Min: 0, Max: 1\n",
      "\n",
      "Row indices within file (event_row_indices.npy):\n",
      "  Shape: (1254,)\n",
      "  Data type: int16\n",
      "  Size in MB: 0.00\n",
      "  First 10 values: [0 1 2 3 4 5 6 7 8 9]\n",
      "  Last 10 values: [244 245 246 247 248 249 250 251 252 253]\n",
      "  Min: 0, Max: 999\n",
      "\n",
      "Number of hits per event (event_num_hits.npy):\n",
      "  Shape: (1254,)\n",
      "  Data type: int16\n",
      "  Size in MB: 0.00\n",
      "  First 10 values: [2836 7081 7539 8339 8038 6452 8371 5445 7043 7489]\n",
      "  Last 10 values: [7896 5350 6678 6074 6385 6552 6272 5985 7087 7341]\n",
      "  Min: 1706, Max: 10035\n",
      "\n",
      "Number of tracks per event (event_num_tracks.npy):\n",
      "  Shape: (1254,)\n",
      "  Data type: int8\n",
      "  Size in MB: 0.00\n",
      "  First 10 values: [2 2 2 2 2 2 2 2 2 2]\n",
      "  Last 10 values: [1 1 2 1 1 1 1 1 1 4]\n",
      "  Min: 1, Max: 4\n",
      "\n",
      "Chunk information (chunk_info.npy):\n",
      "  Shape: (2,)\n",
      "  Data type: object\n",
      "  Size in MB: 0.00\n",
      "  Sample chunk info:\n",
      "    Chunk 0: {'hits_file': 'data/hits0to1000.parquet', 'tracks_file': 'data/tracks0to1000.parquet', 'start_event': 0, 'end_event': 1000, 'count': 1000}\n",
      "    Chunk 1: {'hits_file': 'data/hits1000to1254.parquet', 'tracks_file': 'data/tracks1000to1254.parquet', 'start_event': 1000, 'end_event': 1254, 'count': 254}\n"
     ]
    }
   ],
   "source": [
    "# Read the NumPy index arrays\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NUMPY INDEX ARRAYS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "index_files = {\n",
    "    'event_global_ids.npy': 'Global event IDs',\n",
    "    'event_file_indices.npy': 'File indices (which chunk)',\n",
    "    'event_row_indices.npy': 'Row indices within file',\n",
    "    'event_num_hits.npy': 'Number of hits per event',\n",
    "    'event_num_tracks.npy': 'Number of tracks per event',\n",
    "    'chunk_info.npy': 'Chunk information'\n",
    "}\n",
    "\n",
    "for filename, description in index_files.items():\n",
    "    filepath = os.path.join(dataset_dir, filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        data = np.load(filepath, allow_pickle=True)\n",
    "        print(f\"\\n{description} ({filename}):\")\n",
    "        print(f\"  Shape: {data.shape}\")\n",
    "        print(f\"  Data type: {data.dtype}\")\n",
    "        print(f\"  Size in MB: {data.nbytes / (1024*1024):.2f}\")\n",
    "        \n",
    "        if filename == 'chunk_info.npy':\n",
    "            print(f\"  Sample chunk info:\")\n",
    "            for i, chunk in enumerate(data[:2]):  # Show first 2 chunks\n",
    "                print(f\"    Chunk {i}: {chunk}\")\n",
    "        else:\n",
    "            print(f\"  First 10 values: {data[:10]}\")\n",
    "            if len(data) > 10:\n",
    "                print(f\"  Last 10 values: {data[-10:]}\")\n",
    "                print(f\"  Min: {np.min(data)}, Max: {np.max(data)}\")\n",
    "    else:\n",
    "        print(f\"\\n{description} ({filename}): FILE NOT FOUND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b1ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EFFICIENT EVENT LOOKUP DEMONSTRATION\n",
      "============================================================\n",
      "Total events in dataset: 1254\n",
      "Total chunks: 2\n",
      "\n",
      "Sample event lookups:\n",
      "\n",
      "Event 0:\n",
      "  Global ID: 0\n",
      "  File: data/hits0to1000.parquet\n",
      "  Row in file: 0\n",
      "  Number of hits: 2836\n",
      "  Number of tracks: 2\n",
      "\n",
      "Event 10:\n",
      "  Global ID: 10\n",
      "  File: data/hits0to1000.parquet\n",
      "  Row in file: 10\n",
      "  Number of hits: 8383\n",
      "  Number of tracks: 2\n",
      "\n",
      "Event 100:\n",
      "  Global ID: 100\n",
      "  File: data/hits0to1000.parquet\n",
      "  Row in file: 100\n",
      "  Number of hits: 8793\n",
      "  Number of tracks: 2\n",
      "\n",
      "Event 500:\n",
      "  Global ID: 500\n",
      "  File: data/hits0to1000.parquet\n",
      "  Row in file: 500\n",
      "  Number of hits: 7990\n",
      "  Number of tracks: 1\n",
      "\n",
      "Dataset Statistics:\n",
      "  Total hits: 8741115\n",
      "  Total tracks: 2139\n",
      "  Average hits per event: 6970.59\n",
      "  Average tracks per event: 1.71\n",
      "  Max hits in single event: 10035\n",
      "  Max tracks in single event: 4\n",
      "\n",
      "Events per file:\n",
      "  data/hits0to1000.parquet: 1000 events\n",
      "  data/hits1000to1254.parquet: 254 events\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate efficient event lookup\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EFFICIENT EVENT LOOKUP DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load the index arrays\n",
    "global_ids = np.load(os.path.join(dataset_dir, 'event_global_ids.npy'))\n",
    "file_indices = np.load(os.path.join(dataset_dir, 'event_file_indices.npy'))\n",
    "row_indices = np.load(os.path.join(dataset_dir, 'event_row_indices.npy'))\n",
    "num_hits = np.load(os.path.join(dataset_dir, 'event_num_hits.npy'))\n",
    "num_tracks = np.load(os.path.join(dataset_dir, 'event_num_tracks.npy'))\n",
    "chunk_info = np.load(os.path.join(dataset_dir, 'chunk_info.npy'), allow_pickle=True)\n",
    "\n",
    "print(f\"Total events in dataset: {len(global_ids)}\")\n",
    "print(f\"Total chunks: {len(chunk_info)}\")\n",
    "\n",
    "# Show some example event lookups\n",
    "print(\"\\nSample event lookups:\")\n",
    "sample_indices = [0, 10, 100, min(500, len(global_ids)-1)]\n",
    "\n",
    "for i in sample_indices:\n",
    "    if i < len(global_ids):\n",
    "        global_id = global_ids[i]\n",
    "        file_idx = file_indices[i]\n",
    "        row_idx = row_indices[i]\n",
    "        n_hits = num_hits[i]\n",
    "        n_tracks = num_tracks[i]\n",
    "        \n",
    "        chunk = chunk_info[file_idx]\n",
    "        \n",
    "        print(f\"\\nEvent {i}:\")\n",
    "        print(f\"  Global ID: {global_id}\")\n",
    "        print(f\"  File: {chunk['hits_file']}\")\n",
    "        print(f\"  Row in file: {row_idx}\")\n",
    "        print(f\"  Number of hits: {n_hits}\")\n",
    "        print(f\"  Number of tracks: {n_tracks}\")\n",
    "\n",
    "# Show statistics\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Total hits: {np.sum(num_hits)}\")\n",
    "print(f\"  Total tracks: {np.sum(num_tracks)}\")\n",
    "print(f\"  Average hits per event: {np.mean(num_hits):.2f}\")\n",
    "print(f\"  Average tracks per event: {np.mean(num_tracks):.2f}\")\n",
    "print(f\"  Max hits in single event: {np.max(num_hits)}\")\n",
    "print(f\"  Max tracks in single event: {np.max(num_tracks)}\")\n",
    "\n",
    "# Show file distribution\n",
    "print(f\"\\nEvents per file:\")\n",
    "unique_files, counts = np.unique(file_indices, return_counts=True)\n",
    "for file_idx, count in zip(unique_files, counts):\n",
    "    chunk = chunk_info[file_idx]\n",
    "    print(f\"  {chunk['hits_file']}: {count} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2b257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "root_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
